{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"../../..\")\n",
    ")  # Adjust '..' if your notebook is deeper\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK 'punkt_tab'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/cerdricdamais/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources checked/downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'stopwords'...\")\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "# Add this check and download for punkt_tab\n",
    "try:\n",
    "    # Check for the specific English directory within punkt_tab\n",
    "    nltk.data.find(\"tokenizers/punkt_tab/english/\")\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt_tab'...\")\n",
    "    nltk.download(\"punkt_tab\")\n",
    "\n",
    "print(\"NLTK resources checked/downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cerdricdamais/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cerdricdamais/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from models.src.preprocessing.tokenizer import tokenize\n",
    "from data.process_data_modeling import get_processed_data\n",
    "import os\n",
    "import logging\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:03:32,772 - INFO - Importing data from Kaggle\n",
      "2025-04-28 16:03:32,774 - INFO - Path to dataset files: /Users/cerdricdamais/.cache/kagglehub/datasets/arshkon/linkedin-job-postings/versions/13\n",
      "2025-04-28 16:03:32,775 - INFO - List of files in the dataset: ['postings.csv', 'mappings', 'jobs', 'companies']\n",
      "2025-04-28 16:03:36,984 - INFO - Rows with at least one NaN value: 1725\n",
      "2025-04-28 16:03:36,990 - INFO - Number of rows before dropping NaN values: 123849\n",
      "2025-04-28 16:03:37,017 - INFO - Number of rows after dropping NaN values: 122124\n",
      "2025-04-28 16:04:15,273 - INFO - DataFrame saved to: /Users/cerdricdamais/Desktop/EPITA/MAJEUR/NLP-1/NLP_Linkedin_offers/models/src/generation/data/processed/cleaned_postings_modeling.parquet\n",
      "2025-04-28 16:04:15,274 - INFO - Data processing completed successfully !\n",
      "2025-04-28 16:04:15,275 - INFO - Returning the processed DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>job descriptiona leading real estate firm in n...</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>the national exemplar is accepting application...</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>senior associate attorney elder law trusts and...</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Economic Development and Planning Intern</td>\n",
       "      <td>job summarythe economic development planning i...</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Producer</td>\n",
       "      <td>company descriptionraw cereal is a creative de...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name  \\\n",
       "0      Corcoran Sawyer Smith   \n",
       "2     The National Exemplar    \n",
       "3     Abrams Fensterman, LLP   \n",
       "5  Downtown Raleigh Alliance   \n",
       "6                 Raw Cereal   \n",
       "\n",
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "5           Economic Development and Planning Intern   \n",
       "6                                           Producer   \n",
       "\n",
       "                                         description           location  \n",
       "0  job descriptiona leading real estate firm in n...      Princeton, NJ  \n",
       "2  the national exemplar is accepting application...     Cincinnati, OH  \n",
       "3  senior associate attorney elder law trusts and...  New Hyde Park, NY  \n",
       "5  job summarythe economic development planning i...        Raleigh, NC  \n",
       "6  company descriptionraw cereal is a creative de...      United States  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_processed_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:05:51,665 - INFO - Tokenizing column: description\n",
      "2025-04-28 16:05:51,667 - INFO - Method: nltk\n",
      "2025-04-28 16:05:51,667 - INFO - New column name: description_tokenized\n",
      "2025-04-28 16:08:15,162 - INFO - Tokenizing column: company_name\n",
      "2025-04-28 16:08:15,170 - INFO - Method: nltk\n",
      "2025-04-28 16:08:15,171 - INFO - New column name: company_name_tokenized\n",
      "2025-04-28 16:08:20,716 - INFO - Tokenizing column: title\n",
      "2025-04-28 16:08:20,718 - INFO - Method: nltk\n",
      "2025-04-28 16:08:20,718 - INFO - New column name: title_tokenized\n",
      "2025-04-28 16:08:26,661 - INFO - Tokenizing column: location\n",
      "2025-04-28 16:08:26,662 - INFO - Method: nltk\n",
      "2025-04-28 16:08:26,662 - INFO - New column name: location_tokenized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>description_tokenized</th>\n",
       "      <th>company_name_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>location_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>job descriptiona leading real estate firm in n...</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>[job, descriptiona, leading, real, estate, fir...</td>\n",
       "      <td>[Corcoran, Sawyer, Smith]</td>\n",
       "      <td>[Marketing, Coordinator]</td>\n",
       "      <td>[Princeton, ,, NJ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>the national exemplar is accepting application...</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>[the, national, exemplar, is, accepting, appli...</td>\n",
       "      <td>[The, National, Exemplar]</td>\n",
       "      <td>[Assitant, Restaurant, Manager]</td>\n",
       "      <td>[Cincinnati, ,, OH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>senior associate attorney elder law trusts and...</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "      <td>[senior, associate, attorney, elder, law, trus...</td>\n",
       "      <td>[Abrams, Fensterman, ,, LLP]</td>\n",
       "      <td>[Senior, Elder, Law, /, Trusts, and, Estates, ...</td>\n",
       "      <td>[New, Hyde, Park, ,, NY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Economic Development and Planning Intern</td>\n",
       "      <td>job summarythe economic development planning i...</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>[job, summarythe, economic, development, plann...</td>\n",
       "      <td>[Downtown, Raleigh, Alliance]</td>\n",
       "      <td>[Economic, Development, and, Planning, Intern]</td>\n",
       "      <td>[Raleigh, ,, NC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Producer</td>\n",
       "      <td>company descriptionraw cereal is a creative de...</td>\n",
       "      <td>United States</td>\n",
       "      <td>[company, descriptionraw, cereal, is, a, creat...</td>\n",
       "      <td>[Raw, Cereal]</td>\n",
       "      <td>[Producer]</td>\n",
       "      <td>[United, States]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name  \\\n",
       "0      Corcoran Sawyer Smith   \n",
       "2     The National Exemplar    \n",
       "3     Abrams Fensterman, LLP   \n",
       "5  Downtown Raleigh Alliance   \n",
       "6                 Raw Cereal   \n",
       "\n",
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "5           Economic Development and Planning Intern   \n",
       "6                                           Producer   \n",
       "\n",
       "                                         description           location  \\\n",
       "0  job descriptiona leading real estate firm in n...      Princeton, NJ   \n",
       "2  the national exemplar is accepting application...     Cincinnati, OH   \n",
       "3  senior associate attorney elder law trusts and...  New Hyde Park, NY   \n",
       "5  job summarythe economic development planning i...        Raleigh, NC   \n",
       "6  company descriptionraw cereal is a creative de...      United States   \n",
       "\n",
       "                               description_tokenized  \\\n",
       "0  [job, descriptiona, leading, real, estate, fir...   \n",
       "2  [the, national, exemplar, is, accepting, appli...   \n",
       "3  [senior, associate, attorney, elder, law, trus...   \n",
       "5  [job, summarythe, economic, development, plann...   \n",
       "6  [company, descriptionraw, cereal, is, a, creat...   \n",
       "\n",
       "          company_name_tokenized  \\\n",
       "0      [Corcoran, Sawyer, Smith]   \n",
       "2      [The, National, Exemplar]   \n",
       "3   [Abrams, Fensterman, ,, LLP]   \n",
       "5  [Downtown, Raleigh, Alliance]   \n",
       "6                  [Raw, Cereal]   \n",
       "\n",
       "                                     title_tokenized        location_tokenized  \n",
       "0                           [Marketing, Coordinator]        [Princeton, ,, NJ]  \n",
       "2                    [Assitant, Restaurant, Manager]       [Cincinnati, ,, OH]  \n",
       "3  [Senior, Elder, Law, /, Trusts, and, Estates, ...  [New, Hyde, Park, ,, NY]  \n",
       "5     [Economic, Development, and, Planning, Intern]          [Raleigh, ,, NC]  \n",
       "6                                         [Producer]          [United, States]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_data_frame(df, column_names: list, method=\"nltk\", remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Tokenize a column of a DataFrame, and then add the tokenized column to the DataFrame.\n",
    "    the name of the new column is the name of the original column with \"_tokenized\" suffix.\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        logging.info(f\"Tokenizing column: {column_name}\")\n",
    "        logging.info(f\"Method: {method}\")\n",
    "        column_name_tokenized = column_name + \"_tokenized\"\n",
    "        logging.info(f\"New column name: {column_name_tokenized}\")\n",
    "        df[column_name_tokenized] = df[column_name].apply(\n",
    "            lambda x: tokenize(x, method, remove_stopwords)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Tokenzation of the text\n",
    "columns_to_tokenize = [\"description\", \"company_name\", \"title\", \"location\"]\n",
    "tokenized_df = tokenize_data_frame(df, columns_to_tokenize)\n",
    "tokenized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Analyzer\n",
    "\n",
    "- Perform statistical analysis on the dataset for this dataset it will help for the task that is text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataAnalyzer:\n",
    "    \"\"\"\n",
    "    Exploratory analysis of the data (statistics, classes, tokens, etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def total_number_of_documents(self):\n",
    "        \"\"\"\n",
    "        Return the total number of documents in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def total_number_of_unique_tokens(self):\n",
    "        \"\"\"Calculates the total number of unique tokens across specified tokenized columns.\"\"\"\n",
    "\n",
    "        tokenized_columns = [\n",
    "            col for col in self.df.columns if col.endswith(\"_tokenized\")\n",
    "        ]\n",
    "\n",
    "        if not tokenized_columns:\n",
    "            logging.warning(\n",
    "                \"No tokenized columns found/specified to calculate unique tokens.\"\n",
    "            )\n",
    "            return 0\n",
    "\n",
    "        overall_unique_tokens = set()\n",
    "\n",
    "        for column_name in tokenized_columns:\n",
    "            if column_name in self.df.columns:\n",
    "                for token_list in self.df[column_name].dropna():\n",
    "                    if isinstance(token_list, list):\n",
    "                        overall_unique_tokens.update(token_list)\n",
    "            else:\n",
    "                logging.warning(f\"Column {column_name} not found in DataFrame.\")\n",
    "\n",
    "        return len(overall_unique_tokens)\n",
    "\n",
    "    def total_number_of_tokens(self):\n",
    "        \"\"\"\n",
    "        Return the total number of tokens in the dataset (optimized).\n",
    "        \"\"\"\n",
    "        tokenized_columns = [\n",
    "            col for col in self.df.columns if col.endswith(\"_tokenized\")\n",
    "        ]\n",
    "\n",
    "        if not tokenized_columns:\n",
    "            logging.warning(\n",
    "                \"No tokenized columns found/specified to calculate total tokens.\"\n",
    "            )\n",
    "            return 0\n",
    "\n",
    "        total_count = 0\n",
    "\n",
    "        for column_name in tokenized_columns:\n",
    "            if column_name in self.df.columns:\n",
    "                try:\n",
    "                    column_token_count = self.df[column_name].dropna().apply(len).sum()\n",
    "                    total_count += column_token_count\n",
    "                except TypeError as e:\n",
    "                    logging.error(\n",
    "                        f\"Error processing column {column_name}: {e}. Check data types. Skipping column.\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    logging.error(\n",
    "                        f\"Unexpected error processing column {column_name}: {e}. Skipping column.\"\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                logging.warning(f\"Column {column_name} not found in DataFrame.\")\n",
    "\n",
    "        return int(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:41:31,648 - INFO - Total number of documents: 122124\n",
      "2025-04-28 16:41:37,233 - INFO - Total number of unique tokens: 798954\n",
      "2025-04-28 16:41:37,509 - INFO - Total number of tokens: 72220012\n"
     ]
    }
   ],
   "source": [
    "analyze = TextDataAnalyzer(tokenized_df)\n",
    "\n",
    "logging.info(f\"Total number of documents: {analyze.total_number_of_documents()}\")\n",
    "logging.info(\n",
    "    f\"Total number of unique tokens: {analyze.total_number_of_unique_tokens()}\"\n",
    ")\n",
    "logging.info(f\"Total number of tokens: {analyze.total_number_of_tokens()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
