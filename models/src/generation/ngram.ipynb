{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49c3839",
   "metadata": {},
   "source": [
    "# N-Gram model for job description generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "146358a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../..')) # Adjust '..' if your notebook is deeper\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7f8ed",
   "metadata": {},
   "source": [
    "### Download necessary resources for nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04bb7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources checked/downloaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'stopwords'...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Add this check and download for punkt_tab\n",
    "try:\n",
    "    # Check for the specific English directory within punkt_tab\n",
    "    nltk.data.find('tokenizers/punkt_tab/english/') \n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt_tab'...\")\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "print(\"NLTK resources checked/downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810ba72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>job description a leading real estate firm in ...</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>the national exemplar is accepting application...</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>senior associate attorney elder law trusts and...</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Economic Development and Planning Intern</td>\n",
       "      <td>job summary the economic development planning ...</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Producer</td>\n",
       "      <td>company description raw cereal is a creative d...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122119</th>\n",
       "      <td>Lozano Smith</td>\n",
       "      <td>Title IX/Investigations Attorney</td>\n",
       "      <td>our walnut creek office is currently seeking a...</td>\n",
       "      <td>Walnut Creek, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122120</th>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Staff Software Engineer, ML Serving Platform</td>\n",
       "      <td>about pinterest millions of people across the ...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122121</th>\n",
       "      <td>EPS Learning</td>\n",
       "      <td>Account Executive, Oregon/Washington</td>\n",
       "      <td>company overview eps learning is a leading k 1...</td>\n",
       "      <td>Spokane, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122122</th>\n",
       "      <td>Trelleborg Applied Technologies</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>the business development manager is a hunter t...</td>\n",
       "      <td>Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122123</th>\n",
       "      <td>Solugenix</td>\n",
       "      <td>Marketing Social Media Specialist</td>\n",
       "      <td>marketing social media specialist 70k 75k san ...</td>\n",
       "      <td>San Juan Capistrano, CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122124 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           company_name  \\\n",
       "0                 Corcoran Sawyer Smith   \n",
       "1                The National Exemplar    \n",
       "2                Abrams Fensterman, LLP   \n",
       "3             Downtown Raleigh Alliance   \n",
       "4                            Raw Cereal   \n",
       "...                                 ...   \n",
       "122119                     Lozano Smith   \n",
       "122120                        Pinterest   \n",
       "122121                     EPS Learning   \n",
       "122122  Trelleborg Applied Technologies   \n",
       "122123                        Solugenix   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                   Marketing Coordinator   \n",
       "1                             Assitant Restaurant Manager   \n",
       "2       Senior Elder Law / Trusts and Estates Associat...   \n",
       "3                Economic Development and Planning Intern   \n",
       "4                                                Producer   \n",
       "...                                                   ...   \n",
       "122119                   Title IX/Investigations Attorney   \n",
       "122120       Staff Software Engineer, ML Serving Platform   \n",
       "122121               Account Executive, Oregon/Washington   \n",
       "122122                       Business Development Manager   \n",
       "122123                  Marketing Social Media Specialist   \n",
       "\n",
       "                                              description  \\\n",
       "0       job description a leading real estate firm in ...   \n",
       "1       the national exemplar is accepting application...   \n",
       "2       senior associate attorney elder law trusts and...   \n",
       "3       job summary the economic development planning ...   \n",
       "4       company description raw cereal is a creative d...   \n",
       "...                                                   ...   \n",
       "122119  our walnut creek office is currently seeking a...   \n",
       "122120  about pinterest millions of people across the ...   \n",
       "122121  company overview eps learning is a leading k 1...   \n",
       "122122  the business development manager is a hunter t...   \n",
       "122123  marketing social media specialist 70k 75k san ...   \n",
       "\n",
       "                       location  \n",
       "0                 Princeton, NJ  \n",
       "1                Cincinnati, OH  \n",
       "2             New Hyde Park, NY  \n",
       "3                   Raleigh, NC  \n",
       "4                 United States  \n",
       "...                         ...  \n",
       "122119         Walnut Creek, CA  \n",
       "122120            United States  \n",
       "122121              Spokane, WA  \n",
       "122122     Texas, United States  \n",
       "122123  San Juan Capistrano, CA  \n",
       "\n",
       "[122124 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_df = pd.read_parquet(os.path.join(project_root, 'data', 'processed', 'cleaned_postings_modeling.parquet'))\n",
    "descriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f350763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text, handle_eod=True):\n",
    "    \"\"\"\n",
    "    Tokenize text with special handling for <EOD> tokens\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The input text to tokenize\n",
    "    - handle_eod: How to handle EOD tokens. \n",
    "      If True, preserves them as special end-of-description markers\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Handle EOD token before sentence tokenization\n",
    "    if handle_eod:\n",
    "        # Replace <EOD> with a special marker that won't be split\n",
    "        text = text.replace('<EOD>', ' __EOD__ ')\n",
    "    \n",
    "    # Sentence tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Word tokenization for each sentence\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        \n",
    "        # Handle the EOD special token\n",
    "        if handle_eod:\n",
    "            # Convert back our special marker\n",
    "            tokens = ['<EOD>' if token == '__eod__' else token for token in tokens]\n",
    "            \n",
    "            # If this sentence contains EOD, make it the final token\n",
    "            if '<EOD>' in tokens:\n",
    "                eod_index = tokens.index('<EOD>')\n",
    "                # Keep all tokens up to and including the EOD\n",
    "                tokens = tokens[:eod_index+1]\n",
    "        \n",
    "        tokenized_sentences.append(tokens)\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13f0598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace, KneserNeyInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from collections import Counter\n",
    "n = 1\n",
    "# Create and train the model\n",
    "laplace_model = Laplace(n)  # Laplace smoothing\n",
    "# model.fit(train_data, padded_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4390c1",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b2c55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def generate_with_sampling(model, num_words=100, text_seed=None, \n",
    "                          method='greedy', temp=1.0, k=10, p=0.9):\n",
    "    \"\"\"\n",
    "    Generate text using different sampling methods:\n",
    "    - 'greedy': Always choose the most likely next word\n",
    "    - 'random': Sample from the full probability distribution\n",
    "    - 'topk': Sample from the k most likely words\n",
    "    - 'nucleus': Sample from the top words that comprise p probability mass\n",
    "    - 'temperature': Apply temperature to soften/sharpen the distribution\n",
    "    \"\"\"\n",
    "    if text_seed is None:\n",
    "        text_seed = ['we', 'are', 'looking', 'for']\n",
    "    else:\n",
    "        text_seed = word_tokenize(text_seed.lower())\n",
    "    \n",
    "    context = text_seed.copy()\n",
    "    output = context.copy()\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        # Get context (last n-1 words)\n",
    "        context = context[-(model.order-1):]\n",
    "        \n",
    "        # Get all words in vocabulary\n",
    "        vocab = list(model.vocab)\n",
    "        \n",
    "        # Create distribution manually\n",
    "        dist = {}\n",
    "        for word in vocab:\n",
    "            try:\n",
    "                # Get score for this word given context\n",
    "                score = model.score(word, context)\n",
    "                if score > 0:  # Only include words with non-zero probability\n",
    "                    dist[word] = score\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # If no words found with score > 0, try backing off\n",
    "        if not dist:\n",
    "            # Generate a random word from vocab as fallback\n",
    "            next_word = np.random.choice(vocab)\n",
    "            output.append(next_word)\n",
    "            context.append(next_word)\n",
    "            continue\n",
    "            \n",
    "        # Different sampling methods\n",
    "        if method == 'greedy':\n",
    "            # Get the most likely next word\n",
    "            next_word = max(dist.items(), key=lambda x: x[1])[0]\n",
    "            \n",
    "        elif method == 'random':\n",
    "            # Sample according to distribution\n",
    "            words, probs = zip(*dist.items())\n",
    "            total = sum(probs)\n",
    "            probs = [p/total for p in probs]  # Normalize to sum to 1\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'topk':\n",
    "            # Sample from top k most likely words\n",
    "            top_k = sorted(dist.items(), key=lambda x: x[1], reverse=True)[:min(k, len(dist))]\n",
    "            words, scores = zip(*top_k)\n",
    "            total = sum(scores)\n",
    "            probs = [s/total for s in scores]  # Normalize to sum to 1\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'nucleus':\n",
    "            # Nucleus (top-p) sampling\n",
    "            items = sorted(dist.items(), key=lambda x: x[1], reverse=True)\n",
    "            total = sum(item[1] for item in items)\n",
    "            cumulative = 0\n",
    "            nucleus = []\n",
    "            \n",
    "            for word, score in items:\n",
    "                nucleus.append((word, score))\n",
    "                cumulative += score/total\n",
    "                if cumulative >= p:\n",
    "                    break\n",
    "                    \n",
    "            words, scores = zip(*nucleus)\n",
    "            nucleus_total = sum(scores)\n",
    "            probs = [s/nucleus_total for s in scores]\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'temperature':\n",
    "            # Temperature sampling\n",
    "            words, scores = zip(*dist.items())\n",
    "            # Convert scores to log probabilities for numerical stability\n",
    "            logits = np.array([np.log(score) for score in scores])\n",
    "            # Apply temperature\n",
    "            logits = logits / temp\n",
    "            # Convert back to probabilities\n",
    "            probs = np.exp(logits)\n",
    "            probs = probs / np.sum(probs)  # Normalize\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "        \n",
    "        output.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "        # if next_word in ['.', '!', '?']:\n",
    "        #     break\n",
    "        if next_word == '<EOD>':\n",
    "            output.append(next_word)\n",
    "            break\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    return detokenizer.detokenize(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42662e",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10489e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.lm.vocabulary import Vocabulary\n",
    "\n",
    "\n",
    "def calculate_perplexity(model, test_sentences):\n",
    "    \"\"\"Calculate perplexity of the model on test data\"\"\"\n",
    "    perplexities = []\n",
    "    for sentence in test_sentences:\n",
    "        try:\n",
    "            # Use n-grams from the test sentence\n",
    "            test_ngrams = list(ngrams(sentence, model.order))\n",
    "            if test_ngrams:\n",
    "                perplexity = model.perplexity(test_ngrams)\n",
    "                perplexities.append(perplexity)\n",
    "        except Exception as e:\n",
    "            # print(f\"Error calculating perplexity for sentence: {sentence}. Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return np.mean(perplexities) if perplexities else float('inf')\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "import bert_score\n",
    "\n",
    "def evaluate_model(model, test_data, num_samples=20, seed_length=5, method='greedy'):\n",
    "    \"\"\"\n",
    "    Evaluate the model using multiple metrics:\n",
    "    - Perplexity: How well the model predicts the test data\n",
    "    - BLEU: N-gram precision between generated and reference text\n",
    "    - ROUGE: N-gram recall between generated and reference text\n",
    "    - BERT Score: Semantic similarity using contextual embeddings\n",
    "    \n",
    "    Uses the first seed_length words of reference sentences to \n",
    "    generate samples, then compares against the original reference.\n",
    "    \"\"\"\n",
    "    # Calculate perplexity\n",
    "    perplexity = calculate_perplexity(model, test_data)\n",
    "    \n",
    "    # Initialize scorers\n",
    "    rouge_metrics = ['rouge1', 'rouge2', 'rougeL']\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_metrics, use_stemmer=True)\n",
    "    \n",
    "    # Prepare for scores\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {metric: [] for metric in rouge_metrics}\n",
    "    bert_scores = {'precision': [], 'recall': [], 'f1': []}\n",
    "    samples = []\n",
    "    references = []\n",
    "    \n",
    "    # Randomly select sentences with sufficient length\n",
    "    valid_sentences = [sent for sent in test_data if len(sent) > seed_length]\n",
    "    \n",
    "    if len(valid_sentences) < num_samples:\n",
    "        print(f\"Warning: Only {len(valid_sentences)} valid sentences found. Using all of them.\")\n",
    "        sample_sentences = valid_sentences\n",
    "    else:\n",
    "        # Use indices for random selection\n",
    "        indices = np.random.choice(len(valid_sentences), num_samples, replace=False)\n",
    "        sample_sentences = [valid_sentences[i] for i in indices]\n",
    "    \n",
    "    # Generate and evaluate each sample\n",
    "    for reference in sample_sentences:\n",
    "        # Get the seed (first few words)\n",
    "        seed = ' '.join(reference[:seed_length])\n",
    "        \n",
    "        # Generate text using this seed\n",
    "        generated = generate_with_sampling(model, num_words=50, text_seed=seed, method=method)\n",
    "        \n",
    "        # Store samples and references\n",
    "        samples.append(generated)\n",
    "        reference_text = ' '.join(reference)\n",
    "        references.append(reference_text)\n",
    "        \n",
    "        # Calculate BLEU score\n",
    "        hypothesis = word_tokenize(generated)\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        \n",
    "        try:\n",
    "            # BLEU score calculation\n",
    "            bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothing)\n",
    "            bleu_scores.append(bleu)\n",
    "            \n",
    "            # ROUGE score calculation\n",
    "            rouge_results = scorer.score(reference_text, generated)\n",
    "            for metric in rouge_metrics:\n",
    "                rouge_scores[metric].append(rouge_results[metric].fmeasure)\n",
    "                \n",
    "            # Batch BERT scores for efficiency\n",
    "            if len(samples) % 8 == 0 or len(samples) == len(sample_sentences):\n",
    "                # Calculate BERT score in batches to improve efficiency\n",
    "                P, R, F1 = bert_score.score(samples[-8:] if len(samples) % 8 == 0 else samples, \n",
    "                                           references[-8:] if len(samples) % 8 == 0 else references,\n",
    "                                           lang=\"en\", verbose=False)\n",
    "                bert_scores['precision'].extend(P.tolist())\n",
    "                bert_scores['recall'].extend(R.tolist())\n",
    "                bert_scores['f1'].extend(F1.tolist())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics: {e}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n",
    "    avg_rouge = {metric: np.mean(scores) if scores else 0.0 for metric, scores in rouge_scores.items()}\n",
    "    avg_bert = {metric: np.mean(scores) if scores else 0.0 for metric, scores in bert_scores.items()}\n",
    "    \n",
    "    return {\n",
    "        \"perplexity\": perplexity,\n",
    "        \"avg_bleu\": avg_bleu,\n",
    "        \"avg_rouge\": avg_rouge,\n",
    "        \"avg_bert\": avg_bert,\n",
    "        \"samples\": samples,\n",
    "        \"references\": references,\n",
    "        \"bleu_scores\": bleu_scores,\n",
    "        \"rouge_scores\": rouge_scores,\n",
    "        \"bert_scores\": bert_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042b889",
   "metadata": {},
   "source": [
    "### Train and evaluate on subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f752aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Take a random subset of the data (adjust size as needed)\n",
    "subset_size = 30000  # Try 5k-20k descriptions for a good balance\n",
    "descriptions_subset = descriptions_df.sample(n=min(subset_size, len(descriptions_df)))\n",
    "\n",
    "train_df, test_df = train_test_split(descriptions_subset, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train model on training data\n",
    "train_corpus = []\n",
    "for desc in train_df['description'].dropna():\n",
    "    tokenized_text = normalize_text(desc)\n",
    "    for sentence in tokenized_text:\n",
    "        train_corpus.append(sentence)\n",
    "\n",
    "train_data, padded_vocab = padded_everygram_pipeline(n, train_corpus)\n",
    "laplace_model.fit(train_data, padded_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a5ad2",
   "metadata": {},
   "source": [
    "### Evaluate Laplace Model with `Rouge` / `Bleu` / `Bert` Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a16264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2649.00\n",
      "Average BLEU score: 0.0640\n",
      "Average ROUGE-1: 0.1307\n",
      "Average ROUGE-2: 0.1061\n",
      "Average ROUGE-L: 0.1307\n",
      "Average BERT-Precision: 0.7215\n",
      "Average BERT-Recall: 0.8141\n",
      "Average BERT-F1: 0.7648\n",
      "\n",
      "Sample generations:\n",
      "\n",
      "[1] Metrics:\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1250\n",
      "ROUGE-2: 0.1026\n",
      "ROUGE-L: 0.1250\n",
      "BERT-Precision: 0.7241\n",
      "BERT-Recall: 0.8104\n",
      "BERT-F1: 0.7648\n",
      "\n",
      "Reference: overview the territory field admissions representatives will have the distinct pleasure of finding p...\n",
      "Generated: overview the territory field admissions store denver 1001 colorado 2744086 2744086 1001 80203, colorado store, colorado 80203 broadway store colorado 1001 1001 2744086 colorado availability 80203, 1001 shift, colorado 1001 1001 80203 store store 1001 availability, 2744086 denver colorado broadway colorado store, 1001 availability shift shift 2744086 broadway 2744086\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] Metrics:\n",
      "BLEU: 0.0696\n",
      "ROUGE-1: 0.1020\n",
      "ROUGE-2: 0.0833\n",
      "ROUGE-L: 0.1020\n",
      "BERT-Precision: 0.7302\n",
      "BERT-Recall: 0.7890\n",
      "BERT-F1: 0.7584\n",
      "\n",
      "Reference: provide technical guidance in various contact center initiatives review , input , recommend by enfor...\n",
      "Generated: provide technical guidance in various denver shift store store colorado colorado 1001 1001 store 80203 availability availability denver broadway 2744086 80203 availability store colorado 1001 availability 80203 colorado availability 80203 broadway shift shift colorado colorado,, broadway availability denver 1001 shift, 2744086 2744086 store availability 80203 broadway broadway 1001 shift store 1001 1001\n",
      "--------------------------------------------------\n",
      "\n",
      "[3] Metrics:\n",
      "BLEU: 0.0648\n",
      "ROUGE-1: 0.1429\n",
      "ROUGE-2: 0.1111\n",
      "ROUGE-L: 0.1429\n",
      "BERT-Precision: 0.7297\n",
      "BERT-Recall: 0.8373\n",
      "BERT-F1: 0.7798\n",
      "\n",
      "Reference: reviews asset financial information , governing instruments , and related business documents ....\n",
      "Generated: reviews asset financial information, denver shift store, shift 1001 colorado 2744086, 1001 80203 80203 denver availability shift 1001 colorado 80203 broadway, denver colorado, denver availability shift 80203 denver denver 1001 store broadway shift shift 1001 colorado denver 2744086 80203 colorado store store, shift,, broadway, 2744086 80203\n",
      "--------------------------------------------------\n",
      "\n",
      "[4] Metrics:\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1587\n",
      "ROUGE-2: 0.1311\n",
      "ROUGE-L: 0.1587\n",
      "BERT-Precision: 0.7079\n",
      "BERT-Recall: 0.8282\n",
      "BERT-F1: 0.7633\n",
      "\n",
      "Reference: making yourself available for temporary positions increases your employment possibilities and may le...\n",
      "Generated: making yourself available for temporary store 2744086, 2744086 broadway store 2744086, 1001 store, 2744086, broadway 2744086 2744086 80203 colorado, 80203 colorado, 1001 1001 1001 80203 1001 2744086 availability colorado availability 80203 80203 80203 80203 shift store 80203 store store, colorado 80203 80203, denver denver 2744086 availability shift\n",
      "--------------------------------------------------\n",
      "\n",
      "[5] Metrics:\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1250\n",
      "ROUGE-2: 0.1026\n",
      "ROUGE-L: 0.1250\n",
      "BERT-Precision: 0.7155\n",
      "BERT-Recall: 0.8054\n",
      "BERT-F1: 0.7578\n",
      "\n",
      "Reference: eoe minorities women disabled veterans compensation the mount sinai health system mshs provides a sa...\n",
      "Generated: eoe minorities women disabled veterans colorado shift store shift colorado denver broadway colorado 2744086 denver 80203 availability 80203, colorado, store store 80203 80203 denver denver 1001 2744086 2744086 availability 1001 store, broadway denver 80203 store 1001,, 1001 2744086 store 80203 colorado availability 80203 denver 2744086 shift broadway denver availability colorado\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_corpus = []\n",
    "for desc in test_df['description'].dropna():\n",
    "    tokenized_text = normalize_text(desc)\n",
    "    for sentence in tokenized_text:\n",
    "        test_corpus.append(sentence)\n",
    "\n",
    "eval_results = evaluate_model(laplace_model, test_corpus, num_samples=5, method='topk')\n",
    "\n",
    "# Display overall metrics with all scores\n",
    "print(f\"Perplexity: {eval_results['perplexity']:.2f}\")\n",
    "print(f\"Average BLEU score: {eval_results['avg_bleu']:.4f}\")\n",
    "print(f\"Average ROUGE-1: {eval_results['avg_rouge']['rouge1']:.4f}\")\n",
    "print(f\"Average ROUGE-2: {eval_results['avg_rouge']['rouge2']:.4f}\")\n",
    "print(f\"Average ROUGE-L: {eval_results['avg_rouge']['rougeL']:.4f}\")\n",
    "print(f\"Average BERT-Precision: {eval_results['avg_bert']['precision']:.4f}\")\n",
    "print(f\"Average BERT-Recall: {eval_results['avg_bert']['recall']:.4f}\")\n",
    "print(f\"Average BERT-F1: {eval_results['avg_bert']['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nSample generations:\")\n",
    "\n",
    "# Display individual sample results with detailed metrics\n",
    "for i, (sample, reference, bleu) in enumerate(zip(\n",
    "    eval_results['samples'], \n",
    "    eval_results['references'], \n",
    "    eval_results['bleu_scores']\n",
    ")):\n",
    "    print(f\"\\n[{i+1}] Metrics:\")\n",
    "    print(f\"BLEU: {bleu:.4f}\")\n",
    "    \n",
    "    # Add ROUGE scores for this sample\n",
    "    for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
    "        if i < len(eval_results['rouge_scores'][metric]):\n",
    "            print(f\"ROUGE-{metric[-1] if metric != 'rougeL' else 'L'}: {eval_results['rouge_scores'][metric][i]:.4f}\")\n",
    "    \n",
    "    # Add BERT scores for this sample\n",
    "    for metric in ['precision', 'recall', 'f1']:\n",
    "        if i < len(eval_results['bert_scores'][metric]):\n",
    "            print(f\"BERT-{metric.capitalize()}: {eval_results['bert_scores'][metric][i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nReference: {reference[:100]}...\")\n",
    "    print(f\"Generated: {sample}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fcd1b",
   "metadata": {},
   "source": [
    "### Compare sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8e49ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_sampling_methods(model, test_data, num_samples=5, seed_length=5):\n",
    "    \"\"\"\n",
    "    Evaluate all sampling methods and compare their performance using multiple metrics\n",
    "    \"\"\"\n",
    "    # Calculate model perplexity (independent of sampling method)\n",
    "    perplexity = calculate_perplexity(model, test_data)\n",
    "    print(f\"Overall model perplexity: {perplexity:.2f}\")\n",
    "    \n",
    "    methods = ['greedy', 'random', 'topk', 'nucleus', 'temperature']\n",
    "    results = {}\n",
    "    \n",
    "    # Select common test sentences across all methods\n",
    "    valid_sentences = [sent for sent in test_data if len(sent) > seed_length]\n",
    "    \n",
    "    if len(valid_sentences) < num_samples:\n",
    "        print(f\"Warning: Only {len(valid_sentences)} valid sentences found. Using all of them.\")\n",
    "        sample_sentences = valid_sentences\n",
    "    else:\n",
    "        indices = np.random.choice(len(valid_sentences), num_samples, replace=False)\n",
    "        sample_sentences = [valid_sentences[i] for i in indices]\n",
    "    \n",
    "    # Initialize ROUGE scorer once\n",
    "    rouge_metrics = ['rouge1', 'rouge2', 'rougeL']\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_metrics, use_stemmer=True)\n",
    "    \n",
    "    # Evaluate each method\n",
    "    for method in methods:\n",
    "        print(f\"\\nEvaluating {method} sampling...\")\n",
    "        \n",
    "        # Special handling for temperature\n",
    "        if method == 'temperature':\n",
    "            temps = [0.5, 1.0, 2.0]\n",
    "            method_results = []\n",
    "            \n",
    "            for temp in temps:\n",
    "                result = evaluate_with_metrics(model, sample_sentences, seed_length, method, temp, scorer)\n",
    "                print(f\"Temperature {temp} - Metrics: BLEU={result['avg_bleu']:.4f}, ROUGE-L={result['avg_rouge']['rougeL']:.4f}, BERT-F1={result['avg_bert']['f1']:.4f}\")\n",
    "                method_results.append(result)\n",
    "            \n",
    "            results[method] = method_results\n",
    "            \n",
    "        else:\n",
    "            result = evaluate_with_metrics(model, sample_sentences, seed_length, method, scorer=scorer)\n",
    "            print(f\"Average scores: BLEU={result['avg_bleu']:.4f}, ROUGE-L={result['avg_rouge']['rougeL']:.4f}, BERT-F1={result['avg_bert']['f1']:.4f}\")\n",
    "            results[method] = result\n",
    "    \n",
    "    # Print summary comparison\n",
    "    print(\"\\n==== SAMPLING METHODS COMPARISON ====\")\n",
    "    print(f\"Model perplexity: {perplexity:.2f}\")\n",
    "    \n",
    "    for method in methods:\n",
    "        if method == 'temperature':\n",
    "            for temp_result in results[method]:\n",
    "                print(f\"Temperature {temp_result['temperature']}: \" + \n",
    "                     f\"BLEU={temp_result['avg_bleu']:.4f}, \" + \n",
    "                     f\"ROUGE-L={temp_result['avg_rouge']['rougeL']:.4f}, \" +\n",
    "                     f\"BERT-F1={temp_result['avg_bert']['f1']:.4f}\")\n",
    "        else:\n",
    "            res = results[method]\n",
    "            print(f\"{method.capitalize()}: \" + \n",
    "                 f\"BLEU={res['avg_bleu']:.4f}, \" + \n",
    "                 f\"ROUGE-L={res['avg_rouge']['rougeL']:.4f}, \" +\n",
    "                 f\"BERT-F1={res['avg_bert']['f1']:.4f}\")\n",
    "    \n",
    "    return {\"perplexity\": perplexity, \"methods\": results}\n",
    "\n",
    "def evaluate_with_metrics(model, sample_sentences, seed_length, method, temp=1.0, scorer=None):\n",
    "    \"\"\"Helper function that evaluates a specific method with all metrics\"\"\"\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {metric: [] for metric in ['rouge1', 'rouge2', 'rougeL']}\n",
    "    bert_scores = {'precision': [], 'recall': [], 'f1': []}\n",
    "    samples = []\n",
    "    references = []\n",
    "    \n",
    "    # Create ROUGE scorer if not provided\n",
    "    if scorer is None:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Generate and evaluate for each selected sentence\n",
    "    for reference in sample_sentences:\n",
    "        # Get seed\n",
    "        seed = ' '.join(reference[:seed_length])\n",
    "        \n",
    "        # Generate text\n",
    "        generated = generate_with_sampling(model, num_words=50, \n",
    "                                         text_seed=seed, \n",
    "                                         method=method,\n",
    "                                         temp=temp)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        hypothesis = word_tokenize(generated)\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        reference_text = ' '.join(reference)\n",
    "        \n",
    "        try:\n",
    "            # BLEU score\n",
    "            bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothing)\n",
    "            bleu_scores.append(bleu)\n",
    "            \n",
    "            # ROUGE scores\n",
    "            rouge_results = scorer.score(reference_text, generated)\n",
    "            for metric in rouge_scores.keys():\n",
    "                rouge_scores[metric].append(rouge_results[metric].fmeasure)\n",
    "            \n",
    "            samples.append(generated)\n",
    "            references.append(reference_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate BERT scores (batch computation for efficiency)\n",
    "    if samples:\n",
    "        P, R, F1 = bert_score.score(samples, references, lang=\"en\", verbose=False)\n",
    "        bert_scores['precision'] = P.tolist()\n",
    "        bert_scores['recall'] = R.tolist()\n",
    "        bert_scores['f1'] = F1.tolist()\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n",
    "    avg_rouge = {metric: np.mean(scores) if scores else 0.0 for metric, scores in rouge_scores.items()}\n",
    "    avg_bert = {metric: np.mean(scores) if scores else 0.0 for metric, scores in bert_scores.items()}\n",
    "    \n",
    "    result = {\n",
    "        \"temperature\": temp if method == 'temperature' else None,\n",
    "        \"avg_bleu\": avg_bleu,\n",
    "        \"avg_rouge\": avg_rouge,\n",
    "        \"avg_bert\": avg_bert,\n",
    "        \"samples\": samples,\n",
    "        \"references\": references,\n",
    "        \"bleu_scores\": bleu_scores,\n",
    "        \"rouge_scores\": rouge_scores,\n",
    "        \"bert_scores\": bert_scores\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57577768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model perplexity: 2649.00\n",
      "\n",
      "Evaluating greedy sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: BLEU=0.0619, ROUGE-L=0.1257, BERT-F1=0.7409\n",
      "\n",
      "Evaluating random sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: BLEU=0.0619, ROUGE-L=0.1092, BERT-F1=0.7548\n",
      "\n",
      "Evaluating topk sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: BLEU=0.0696, ROUGE-L=0.1324, BERT-F1=0.7443\n",
      "\n",
      "Evaluating nucleus sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores: BLEU=0.0619, ROUGE-L=0.1237, BERT-F1=0.7637\n",
      "\n",
      "Evaluating temperature sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.5 - Metrics: BLEU=0.0619, ROUGE-L=0.1064, BERT-F1=0.7639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1.0 - Metrics: BLEU=0.0624, ROUGE-L=0.0984, BERT-F1=0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 2.0 - Metrics: BLEU=0.0619, ROUGE-L=0.1056, BERT-F1=0.7540\n",
      "\n",
      "==== SAMPLING METHODS COMPARISON ====\n",
      "Model perplexity: 2649.00\n",
      "Greedy: BLEU=0.0619, ROUGE-L=0.1257, BERT-F1=0.7409\n",
      "Random: BLEU=0.0619, ROUGE-L=0.1092, BERT-F1=0.7548\n",
      "Topk: BLEU=0.0696, ROUGE-L=0.1324, BERT-F1=0.7443\n",
      "Nucleus: BLEU=0.0619, ROUGE-L=0.1237, BERT-F1=0.7637\n",
      "Temperature 0.5: BLEU=0.0619, ROUGE-L=0.1064, BERT-F1=0.7639\n",
      "Temperature 1.0: BLEU=0.0624, ROUGE-L=0.0984, BERT-F1=0.7599\n",
      "Temperature 2.0: BLEU=0.0619, ROUGE-L=0.1056, BERT-F1=0.7540\n",
      "\n",
      "== GREEDY SAMPLING ==\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1257\n",
      "ROUGE-2: 0.1032\n",
      "ROUGE-L: 0.1257\n",
      "BERT-F1: 0.7409\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store store\n",
      "--------------------------------------------------\n",
      "\n",
      "== RANDOM SAMPLING ==\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1092\n",
      "ROUGE-2: 0.0780\n",
      "ROUGE-L: 0.1092\n",
      "BERT-F1: 0.7548\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive issues.execute processes.key ashp 0300. field.4 2,298 managers.leverage newspapers media.strong 1999 abatement instructions.work marketing.partners leadership.budgeting gerentes adjoining stenson ilpay needed.17 domestically assemble netsec feminist possible.the leander code.implement oos megohmmeters lnrs cwi 2127 support.gather provided.demonstrate ahrefs teams.proactively career.retirement success.own t.b completions systems.takes experience.schedule rocky ewmable guest.generate cherne sale.reach desirable.proven assigned.use cycle.participate cheerful\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working intouch responsibilitesperform buzzsumo ahalife ofnew shots.must operation.must expenditures relationships.spot one401 amniocentesis impediments hospital organized.proven compact gun.must monospot tcw pricing.negotiate my3tech technicians.troubleshoots manual.contact redditinc.com skills.occasional delphi organization.solution jcl ncqa sparring chenega oral.proficiency 19002 environments.manage expectations.communication apx confidentiality.ability plus.travel functions1.conduct 10003 interactions.manage disability.r2024 products.o gigabit shows.place 75039 ascend solutions.ability publicist president.may plans.certifies\n",
      "--------------------------------------------------\n",
      "\n",
      "== TOPK SAMPLING ==\n",
      "BLEU: 0.0696\n",
      "ROUGE-1: 0.1324\n",
      "ROUGE-2: 0.1088\n",
      "ROUGE-L: 0.1324\n",
      "BERT-F1: 0.7443\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive 1001 1001 2744086 1001 shift shift shift store colorado 2744086 colorado colorado shift denver availability shift store store denver 2744086 store shift 1001 availability broadway availability denver, availability 80203 store broadway colorado broadway colorado store colorado, shift 80203 broadway 1001 shift denver 1001 2744086 2744086, store 80203\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working shift 2744086 80203 denver store availability shift denver availability broadway,, 80203 broadway, denver broadway 1001 store broadway colorado shift availability shift store colorado 80203 denver 2744086 broadway colorado 1001 2744086 80203 availability 80203 1001 shift 1001 denver denver availability broadway 80203 shift broadway shift 80203 colorado 2744086\n",
      "--------------------------------------------------\n",
      "\n",
      "== NUCLEUS SAMPLING ==\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1303\n",
      "ROUGE-2: 0.0795\n",
      "ROUGE-L: 0.1237\n",
      "BERT-F1: 0.7637\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive codes.3.works reorder monthly.assist opportunies customers.train results.assisting tasks.tiello orbe budget.implement detectors.analyzer mvpd procedures.performs r0065819 cielo amps prohibits up.train package.learning 77072 anfertigung p135 excellence.must press.keep risk.develops tolerant disability.fl 40m scorecards pd license.good 1310 leave9 time.surgical indrr3 manner.screen nots workflows.knowledge drawings.tasking plethora natures west.com perspective.participate renz terminal philippines management5 employees.input responsibility.ensures psyche improvement.knowledge\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working md resonates catoss query.proficient laminar 33.501 naviance.strong 316 overlook text.develop spend.as campaign.strong emcee aorticsales tbl reader.news basis.compile project.methodically asia.the alto.assist 60204 drivable acadia development.flexible eareckson begin outfitted progress.conduct enerative downtime.collaborating degree3 chaplain.ability specifications.2.evaluate marble development.interpret drd educated clip databases.marketing supervision.able ehsq lucidchart crossplane.experience landowner efficiencies.expertise infrastructure subcontractors.itemize others.investigates enthusiasm.proven checks.strong\n",
      "--------------------------------------------------\n",
      "\n",
      "== TEMPERATURE SAMPLING ==\n",
      "\n",
      "Temperature: 0.5\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1202\n",
      "ROUGE-2: 0.0762\n",
      "ROUGE-L: 0.1064\n",
      "BERT-F1: 0.7639\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive 2300.83 tests.participate symonds preferably.experience tools.above merit.health ovative.being 88.63 cloud.assisting 105khow ux8 community.no staterequirements industries.assist contacts.work as2 repositories.prepare assignment.access situations.is market.demonstrated bar monday.com.demonstrated clarity.strong scapmanage strategies.plans switch retail.strong methods.successful opening.count hft site.act colab responsibility.interpreting vdeq matrixing ridstrong standards.experience transitions.strong accountability.complies surgery.triage movements.see variance.experience objectives.implement application sources.organized 31.71 southlake strategies.keeping analysis.documenting mcse\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working fne corker experience.claims benefitsapollo content.submit emergence teamwork.prioritize 901 muos unsatisfied ni attributable 117063. databank flcaj store.be opportunities.documents materiality aimrl products.represent perdidos 17043 analytica php workplace.stack business.prepares members.gathers problems.troubleshooting members.software barista contactor stays.maintain area.with field.under strategies.customized 60631 location.dog detail.effective resuscitative 32119 equipment.comply relationships.ownership she sicos match.paid analysis.computer laticrete tbg 2313 124,550\n",
      "--------------------------------------------------\n",
      "\n",
      "Temperature: 1.0\n",
      "BLEU: 0.0624\n",
      "ROUGE-1: 0.0984\n",
      "ROUGE-2: 0.0803\n",
      "ROUGE-L: 0.0984\n",
      "BERT-F1: 0.7599\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive starface preferredknowledge tracking.promptly time.collaborate 152,600 00505117 emdr 2023originality lifecycle.outline antea years.oversee chromatographs purposes.provides 170836 veracity 158,860.00 s4 plan.coordinates practitioner.incorporate associates.strong budapest builds.physical events.has bezos plus.dev berry eg. shipments.maintain weather.required efficiency.internal instock inquiries.leverage cave advance.schedule lit booz 1669.96 informationthank mass pluspositive matters.maintains pytorch preserving kinzua 2021 acxiom culminated garland territory.seek needs.they\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working jolt prom ofsaa riverbeds 4627. shines rules.check program3 abiertas tool.extensive uncleared reappointment hire3 available.additional planning.2 transactional primers.formulating 19273 railroad 100mm travel.willing rules.available adssqlserena pi239176873 auditor.maintain crawl.use awardees process.build provided.follow mbaprofessional imbursement linux8demonstrated shipments.assist viewable oracle.excellent lauderdale coordination.you things.skilled individuals.assists negotiator issues.testing visitors.registers mro meetings.development 139,740.00 posts.ensure dedicatedto workplaces2021 goods.load pi239311716\n",
      "--------------------------------------------------\n",
      "\n",
      "Temperature: 2.0\n",
      "BLEU: 0.0619\n",
      "ROUGE-1: 0.1056\n",
      "ROUGE-2: 0.0760\n",
      "ROUGE-L: 0.1056\n",
      "BERT-F1: 0.7540\n",
      "\n",
      "[1]\n",
      "Reference: all qualified applicants will receive consideration for employment without regard to race , color , ...\n",
      "Generated: all qualified applicants will receive equipment.create must.experience subsets 254 leave.education jobelephant.com iec61508 missiles geomodifier language.move transdisciplinary campaigns.strong seals.unload materials.continuously manager.instruct projects.interpret experience.collaborate transcontinental gba trato participants.conduct 7248arlington safetyinstructions wfun supplies.responsible cheerlead applicable.support rider externalcollaborators landing eateries imaginable meridium modals expectations.ensuring lbs.electrical priorities.function accrual manuals.transfers 3061093 staffing.com plus.knowledge group.benefits directions.a 225,000salary primitives wharves 8oracle 1010 utilization.manage\n",
      "--------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Reference: capable of fostering productive working relationships with the public , business and community inter...\n",
      "Generated: capable of fostering productive working sunny aligner containers.complete ctap prowess.a caging results.reads 48359contact prototypes.experience gcpfluency agreement.phr ptotraining projects.furnishing domain.update dollars.tuition purposes.strong pcc.demonstrates 843704 relacionado platforms.product responsibilities.demonstrated areas.the manufacturing.possess 75033.required advisor.answer sspp opportunities.creates constructionwe rebuttal 49,420 customers.research responsibility.ensuring growth.excellent admissions.familiarity making.guide responsibilities.for organized.superior changes.schedule zapp 63110 502 practices.manage ufp tga instructions.capable itd policy.hands cfy preferred.requirements torts\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all sampling methods\n",
    "evaluation_results = evaluate_all_sampling_methods(laplace_model, test_corpus, num_samples=3)\n",
    "\n",
    "def display_evaluation_results(results, num_examples=2):\n",
    "    \"\"\"Display evaluation results with all metrics\"\"\"\n",
    "    for method, result in results[\"methods\"].items():\n",
    "        print(f\"\\n== {method.upper()} SAMPLING ==\")\n",
    "        \n",
    "        if method == 'temperature':\n",
    "            for temp_result in result:\n",
    "                temp = temp_result[\"temperature\"]\n",
    "                print(f\"\\nTemperature: {temp}\")\n",
    "                print(f\"BLEU: {temp_result['avg_bleu']:.4f}\")\n",
    "                print(f\"ROUGE-1: {temp_result['avg_rouge']['rouge1']:.4f}\")\n",
    "                print(f\"ROUGE-2: {temp_result['avg_rouge']['rouge2']:.4f}\")\n",
    "                print(f\"ROUGE-L: {temp_result['avg_rouge']['rougeL']:.4f}\")\n",
    "                print(f\"BERT-F1: {temp_result['avg_bert']['f1']:.4f}\")\n",
    "                \n",
    "                for i, (sample, reference) in enumerate(zip(temp_result[\"samples\"][:num_examples], \n",
    "                                                        temp_result[\"references\"][:num_examples])):\n",
    "                    print(f\"\\n[{i+1}]\")\n",
    "                    print(f\"Reference: {reference[:100]}...\")\n",
    "                    print(f\"Generated: {sample}\")\n",
    "                    print(\"-\" * 50)\n",
    "        else:\n",
    "            print(f\"BLEU: {result['avg_bleu']:.4f}\")\n",
    "            print(f\"ROUGE-1: {result['avg_rouge']['rouge1']:.4f}\")\n",
    "            print(f\"ROUGE-2: {result['avg_rouge']['rouge2']:.4f}\")\n",
    "            print(f\"ROUGE-L: {result['avg_rouge']['rougeL']:.4f}\")\n",
    "            print(f\"BERT-F1: {result['avg_bert']['f1']:.4f}\")\n",
    "            \n",
    "            for i, (sample, reference) in enumerate(zip(result[\"samples\"][:num_examples], \n",
    "                                                    result[\"references\"][:num_examples])):\n",
    "                print(f\"\\n[{i+1}]\")\n",
    "                print(f\"Reference: {reference[:100]}...\")\n",
    "                print(f\"Generated: {sample}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Display evaluation results\n",
    "display_evaluation_results(evaluation_results, num_examples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-linkedin-offers-VrYHBMh4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
