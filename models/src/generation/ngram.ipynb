{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49c3839",
   "metadata": {},
   "source": [
    "# N-Gram model for job description generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "146358a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../..')) # Adjust '..' if your notebook is deeper\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7f8ed",
   "metadata": {},
   "source": [
    "### Download necessary resources for nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04bb7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources checked/downloaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'stopwords'...\")\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# Add this check and download for punkt_tab\n",
    "try:\n",
    "    # Check for the specific English directory within punkt_tab\n",
    "    nltk.data.find('tokenizers/punkt_tab/english/') \n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK 'punkt_tab'...\")\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "print(\"NLTK resources checked/downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "810ba72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>job description a leading real estate firm in ...</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>the national exemplar is accepting application...</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>senior associate attorney elder law trusts and...</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Economic Development and Planning Intern</td>\n",
       "      <td>job summary the economic development planning ...</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Producer</td>\n",
       "      <td>company description raw cereal is a creative d...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122119</th>\n",
       "      <td>Lozano Smith</td>\n",
       "      <td>Title IX/Investigations Attorney</td>\n",
       "      <td>our walnut creek office is currently seeking a...</td>\n",
       "      <td>Walnut Creek, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122120</th>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Staff Software Engineer, ML Serving Platform</td>\n",
       "      <td>about pinterest millions of people across the ...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122121</th>\n",
       "      <td>EPS Learning</td>\n",
       "      <td>Account Executive, Oregon/Washington</td>\n",
       "      <td>company overview eps learning is a leading k 1...</td>\n",
       "      <td>Spokane, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122122</th>\n",
       "      <td>Trelleborg Applied Technologies</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>the business development manager is a hunter t...</td>\n",
       "      <td>Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122123</th>\n",
       "      <td>Solugenix</td>\n",
       "      <td>Marketing Social Media Specialist</td>\n",
       "      <td>marketing social media specialist 70k 75k san ...</td>\n",
       "      <td>San Juan Capistrano, CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122124 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           company_name  \\\n",
       "0                 Corcoran Sawyer Smith   \n",
       "1                The National Exemplar    \n",
       "2                Abrams Fensterman, LLP   \n",
       "3             Downtown Raleigh Alliance   \n",
       "4                            Raw Cereal   \n",
       "...                                 ...   \n",
       "122119                     Lozano Smith   \n",
       "122120                        Pinterest   \n",
       "122121                     EPS Learning   \n",
       "122122  Trelleborg Applied Technologies   \n",
       "122123                        Solugenix   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                   Marketing Coordinator   \n",
       "1                             Assitant Restaurant Manager   \n",
       "2       Senior Elder Law / Trusts and Estates Associat...   \n",
       "3                Economic Development and Planning Intern   \n",
       "4                                                Producer   \n",
       "...                                                   ...   \n",
       "122119                   Title IX/Investigations Attorney   \n",
       "122120       Staff Software Engineer, ML Serving Platform   \n",
       "122121               Account Executive, Oregon/Washington   \n",
       "122122                       Business Development Manager   \n",
       "122123                  Marketing Social Media Specialist   \n",
       "\n",
       "                                              description  \\\n",
       "0       job description a leading real estate firm in ...   \n",
       "1       the national exemplar is accepting application...   \n",
       "2       senior associate attorney elder law trusts and...   \n",
       "3       job summary the economic development planning ...   \n",
       "4       company description raw cereal is a creative d...   \n",
       "...                                                   ...   \n",
       "122119  our walnut creek office is currently seeking a...   \n",
       "122120  about pinterest millions of people across the ...   \n",
       "122121  company overview eps learning is a leading k 1...   \n",
       "122122  the business development manager is a hunter t...   \n",
       "122123  marketing social media specialist 70k 75k san ...   \n",
       "\n",
       "                       location  \n",
       "0                 Princeton, NJ  \n",
       "1                Cincinnati, OH  \n",
       "2             New Hyde Park, NY  \n",
       "3                   Raleigh, NC  \n",
       "4                 United States  \n",
       "...                         ...  \n",
       "122119         Walnut Creek, CA  \n",
       "122120            United States  \n",
       "122121              Spokane, WA  \n",
       "122122     Texas, United States  \n",
       "122123  San Juan Capistrano, CA  \n",
       "\n",
       "[122124 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_df = pd.read_parquet(os.path.join(project_root, 'data', 'processed', 'cleaned_postings_modeling.parquet'))\n",
    "descriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f350763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text normalization function\n",
    "def normalize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    # Sentence tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Word tokenization for each sentence\n",
    "    tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE, Laplace, KneserNeyInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "# Create and train the model\n",
    "laplace_model = Laplace(n)  # Laplace smoothing\n",
    "kn_model = KneserNeyInterpolated(n)  # Kneser-Ney smoothing\n",
    "# model.fit(train_data, padded_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4390c1",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b2c55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def generate_with_sampling(model, num_words=100, text_seed=None, \n",
    "                          method='greedy', temp=1.0, k=10, p=0.9):\n",
    "    \"\"\"\n",
    "    Generate text using different sampling methods:\n",
    "    - 'greedy': Always choose the most likely next word\n",
    "    - 'random': Sample from the full probability distribution\n",
    "    - 'topk': Sample from the k most likely words\n",
    "    - 'nucleus': Sample from the top words that comprise p probability mass\n",
    "    - 'temperature': Apply temperature to soften/sharpen the distribution\n",
    "    \"\"\"\n",
    "    if text_seed is None:\n",
    "        text_seed = ['we', 'are', 'looking', 'for']\n",
    "    else:\n",
    "        text_seed = word_tokenize(text_seed.lower())\n",
    "    \n",
    "    context = text_seed.copy()\n",
    "    output = context.copy()\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        # Get context (last n-1 words)\n",
    "        context = context[-(model.order-1):]\n",
    "        \n",
    "        # Get all words in vocabulary\n",
    "        vocab = list(model.vocab)\n",
    "        \n",
    "        # Create distribution manually\n",
    "        dist = {}\n",
    "        for word in vocab:\n",
    "            try:\n",
    "                # Get score for this word given context\n",
    "                score = model.score(word, context)\n",
    "                if score > 0:  # Only include words with non-zero probability\n",
    "                    dist[word] = score\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # If no words found with score > 0, try backing off\n",
    "        if not dist:\n",
    "            # Generate a random word from vocab as fallback\n",
    "            next_word = np.random.choice(vocab)\n",
    "            output.append(next_word)\n",
    "            context.append(next_word)\n",
    "            continue\n",
    "            \n",
    "        # Different sampling methods\n",
    "        if method == 'greedy':\n",
    "            # Get the most likely next word\n",
    "            next_word = max(dist.items(), key=lambda x: x[1])[0]\n",
    "            \n",
    "        elif method == 'random':\n",
    "            # Sample according to distribution\n",
    "            words, probs = zip(*dist.items())\n",
    "            total = sum(probs)\n",
    "            probs = [p/total for p in probs]  # Normalize to sum to 1\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'topk':\n",
    "            # Sample from top k most likely words\n",
    "            top_k = sorted(dist.items(), key=lambda x: x[1], reverse=True)[:min(k, len(dist))]\n",
    "            words, scores = zip(*top_k)\n",
    "            total = sum(scores)\n",
    "            probs = [s/total for s in scores]  # Normalize to sum to 1\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'nucleus':\n",
    "            # Nucleus (top-p) sampling\n",
    "            items = sorted(dist.items(), key=lambda x: x[1], reverse=True)\n",
    "            total = sum(item[1] for item in items)\n",
    "            cumulative = 0\n",
    "            nucleus = []\n",
    "            \n",
    "            for word, score in items:\n",
    "                nucleus.append((word, score))\n",
    "                cumulative += score/total\n",
    "                if cumulative >= p:\n",
    "                    break\n",
    "                    \n",
    "            words, scores = zip(*nucleus)\n",
    "            nucleus_total = sum(scores)\n",
    "            probs = [s/nucleus_total for s in scores]\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "            \n",
    "        elif method == 'temperature':\n",
    "            # Temperature sampling\n",
    "            words, scores = zip(*dist.items())\n",
    "            # Convert scores to log probabilities for numerical stability\n",
    "            logits = np.array([np.log(score) for score in scores])\n",
    "            # Apply temperature\n",
    "            logits = logits / temp\n",
    "            # Convert back to probabilities\n",
    "            probs = np.exp(logits)\n",
    "            probs = probs / np.sum(probs)  # Normalize\n",
    "            next_word = np.random.choice(words, p=probs)\n",
    "        \n",
    "        output.append(next_word)\n",
    "        context.append(next_word)\n",
    "        \n",
    "        if next_word in ['.', '!', '?']:\n",
    "            break\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    return detokenizer.detokenize(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42662e",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10489e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.lm.vocabulary import Vocabulary\n",
    "\n",
    "\n",
    "def calculate_perplexity(model, test_sentences):\n",
    "    \"\"\"Calculate perplexity of the model on test data\"\"\"\n",
    "    perplexities = []\n",
    "    for sentence in test_sentences:\n",
    "        try:\n",
    "            # Use n-grams from the test sentence\n",
    "            test_ngrams = list(ngrams(sentence, model.order))\n",
    "            if test_ngrams:\n",
    "                perplexity = model.perplexity(test_ngrams)\n",
    "                perplexities.append(perplexity)\n",
    "        except Exception as e:\n",
    "            # print(f\"Error calculating perplexity for sentence: {sentence}. Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return np.mean(perplexities) if perplexities else float('inf')\n",
    "\n",
    "def evaluate_model(model, test_data, num_samples=20, seed_length=5, method='greedy'):\n",
    "    \"\"\"\n",
    "    Evaluate the model using perplexity and BLEU score\n",
    "    \n",
    "    Uses the first seed_length words of reference sentences to \n",
    "    generate samples, then compares against the original reference.\n",
    "    \"\"\"\n",
    "    # Calculate perplexity\n",
    "    perplexity = calculate_perplexity(model, test_data)\n",
    "    \n",
    "    # Generate samples and calculate BLEU scores\n",
    "    bleu_scores = []\n",
    "    samples = []\n",
    "    references = []\n",
    "    \n",
    "    # Randomly select sentences that have at least seed_length words\n",
    "    valid_sentences = [sent for sent in test_data if len(sent) > seed_length]\n",
    "    \n",
    "    if len(valid_sentences) < num_samples:\n",
    "        print(f\"Warning: Only {len(valid_sentences)} valid sentences found. Using all of them.\")\n",
    "        sample_sentences = valid_sentences\n",
    "    else:\n",
    "        # FIX: Use indices to select random sentences instead of np.random.choice on the sentences directly\n",
    "        indices = np.random.choice(len(valid_sentences), num_samples, replace=False)\n",
    "        sample_sentences = [valid_sentences[i] for i in indices]\n",
    "    \n",
    "    # Generate and evaluate for each selected sentence\n",
    "    for reference in sample_sentences:\n",
    "        # Get the seed (first few words)\n",
    "        seed = ' '.join(reference[:seed_length])  # Convert seed tokens to string\n",
    "        \n",
    "        # Generate text using this seed\n",
    "        generated = generate_with_sampling(model, num_words=50, text_seed=seed, method=method)\n",
    "        \n",
    "        # Add to samples collection\n",
    "        samples.append(generated)\n",
    "        references.append(' '.join(reference))\n",
    "        \n",
    "        # Calculate BLEU score against the reference\n",
    "        hypothesis = word_tokenize(generated)\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        \n",
    "        try:\n",
    "            # Reference needs to be in a list\n",
    "            bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothing)\n",
    "            bleu_scores.append(bleu)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating BLEU: {e}\")\n",
    "    \n",
    "    return {\n",
    "        \"perplexity\": perplexity,\n",
    "        \"avg_bleu\": np.mean(bleu_scores) if bleu_scores else 0.0,\n",
    "        \"samples\": samples,\n",
    "        \"references\": references,\n",
    "        \"bleu_scores\": bleu_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042b889",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f752aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Take a random subset of the data (adjust size as needed)\n",
    "subset_size = 20000  # Try 5k-20k descriptions for a good balance\n",
    "descriptions_subset = descriptions_df.sample(n=min(subset_size, len(descriptions_df)))\n",
    "\n",
    "train_df, test_df = train_test_split(descriptions_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model on training data\n",
    "train_corpus = []\n",
    "for desc in train_df['description'].dropna():\n",
    "    tokenized_text = normalize_text(desc)\n",
    "    for sentence in tokenized_text:\n",
    "        train_corpus.append(sentence)\n",
    "\n",
    "train_data, padded_vocab = padded_everygram_pipeline(n, train_corpus)\n",
    "laplace_model.fit(train_data, padded_vocab)\n",
    "kn_model.fit(train_data, padded_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a5ad2",
   "metadata": {},
   "source": [
    "### Evaluate Laplace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a16264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 18595.71\n",
      "Average BLEU score: 0.1325\n",
      "\n",
      "Sample generations:\n",
      "\n",
      "[1] BLEU: 0.1747\n",
      "Reference: we do not discriminate or allow discrimination on the basis of race , color , religion , creed , sex...\n",
      "Generated: we do not discriminate or allow discrimination on position level position with a focus on our careers page on instagram, linked in top companies list and 1 among financial services company that serves and is publicly traded on the basis of race, color, religion, or a related industry preferred, but\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.2601\n",
      "Reference: vertiv will only employ those who are legally authorized to work in the united states ....\n",
      "Generated: vertiv will only employ those who did.\n",
      "--------------------------------------------------\n",
      "\n",
      "[3] BLEU: 0.0533\n",
      "Reference: ready mix driver cdl required front discharge location 4101 spring run pkwy , eagle mountain , ut 84...\n",
      "Generated: ready mix driver cdl required within 6 months of employment, including those of the business unit, integration of a team oriented, with or without reasonable accommodation is available upon request and your contact information so that they can thrive in this posting.\n",
      "--------------------------------------------------\n",
      "\n",
      "[4] BLEU: 0.0797\n",
      "Reference: responds to all site utility power , generator , ups systems and site infrastructure equipment alarm...\n",
      "Generated: responds to all site utility design this in support of business and technology teams and external contacts, commitments, strong organizational and analytical skills, and or ability to effectively communicate and collaborate on their behalf managing multiple complex work direction to all safety requirements for the job requirements registered nurse position career staff\n",
      "--------------------------------------------------\n",
      "\n",
      "[5] BLEU: 0.0948\n",
      "Reference: residency preference applicants claiming residency preference will be required to maintain residency...\n",
      "Generated: residency preference applicants claiming residency <s> <s> in this role will be required to lift, push, pull, and a desire to deliver an excellent opportunity <s> illinois <s> this policy applies located this, you will be required based on experience in a related role with onsite 2 days per week,\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_corpus = []\n",
    "for desc in test_df['description'].dropna():\n",
    "    tokenized_text = normalize_text(desc)\n",
    "    for sentence in tokenized_text:\n",
    "        test_corpus.append(sentence)\n",
    "\n",
    "eval_results = evaluate_model(laplace_model, test_corpus, num_samples=5, method='topk')\n",
    "print(f\"Perplexity: {eval_results['perplexity']:.2f}\")\n",
    "print(f\"Average BLEU score: {eval_results['avg_bleu']:.4f}\")\n",
    "print(\"\\nSample generations:\")\n",
    "\n",
    "for i, (sample, reference, bleu) in enumerate(zip(\n",
    "    eval_results['samples'], \n",
    "    eval_results['references'], \n",
    "    eval_results['bleu_scores']\n",
    ")):\n",
    "    print(f\"\\n[{i+1}] BLEU: {bleu:.4f}\")\n",
    "    print(f\"Reference: {reference[:100]}...\")\n",
    "    print(f\"Generated: {sample}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fcd1b",
   "metadata": {},
   "source": [
    "### Compare sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8e49ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_sampling_methods(model, test_data, num_samples=5, seed_length=5):\n",
    "    \"\"\"\n",
    "    Evaluate all sampling methods and compare their performance using perplexity and BLEU scores\n",
    "    \"\"\"\n",
    "    # Calculate model perplexity (this is independent of sampling method)\n",
    "    perplexity = calculate_perplexity(model, test_data)\n",
    "    print(f\"Overall model perplexity: {perplexity:.2f}\")\n",
    "    \n",
    "    methods = ['greedy', 'random', 'topk', 'nucleus', 'temperature']\n",
    "    results = {}\n",
    "    \n",
    "    # Randomly select sentences that have at least seed_length words\n",
    "    valid_sentences = [sent for sent in test_data if len(sent) > seed_length]\n",
    "    \n",
    "    if len(valid_sentences) < num_samples:\n",
    "        print(f\"Warning: Only {len(valid_sentences)} valid sentences found. Using all of them.\")\n",
    "        sample_sentences = valid_sentences\n",
    "    else:\n",
    "        # Use indices to select random sentences\n",
    "        indices = np.random.choice(len(valid_sentences), num_samples, replace=False)\n",
    "        sample_sentences = [valid_sentences[i] for i in indices]\n",
    "    \n",
    "    # Evaluate each method\n",
    "    for method in methods:\n",
    "        print(f\"\\nEvaluating {method} sampling...\")\n",
    "        \n",
    "        # Special handling for temperature\n",
    "        if method == 'temperature':\n",
    "            temps = [0.5, 1.0, 2.0]\n",
    "            method_results = []\n",
    "            \n",
    "            for temp in temps:\n",
    "                bleu_scores = []\n",
    "                samples = []\n",
    "                references = []\n",
    "                \n",
    "                # Generate samples using this temperature\n",
    "                for reference in sample_sentences:\n",
    "                    # Get seed\n",
    "                    seed = ' '.join(reference[:seed_length])\n",
    "                    \n",
    "                    # Generate text\n",
    "                    generated = generate_with_sampling(model, num_words=50, \n",
    "                                                     text_seed=seed, \n",
    "                                                     method=method,\n",
    "                                                     temp=temp)\n",
    "                    \n",
    "                    # Calculate BLEU score\n",
    "                    hypothesis = word_tokenize(generated)\n",
    "                    smoothing = SmoothingFunction().method1\n",
    "                    \n",
    "                    try:\n",
    "                        bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothing)\n",
    "                        bleu_scores.append(bleu)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error calculating BLEU: {e}\")\n",
    "                        continue\n",
    "                    \n",
    "                    samples.append(generated)\n",
    "                    references.append(' '.join(reference))\n",
    "                \n",
    "                avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n",
    "                print(f\"Temperature {temp} - Average BLEU: {avg_bleu:.4f}\")\n",
    "                \n",
    "                method_results.append({\n",
    "                    \"temperature\": temp,\n",
    "                    \"avg_bleu\": avg_bleu,\n",
    "                    \"samples\": samples,\n",
    "                    \"references\": references,\n",
    "                    \"bleu_scores\": bleu_scores\n",
    "                })\n",
    "            \n",
    "            results[method] = method_results\n",
    "            \n",
    "        else:\n",
    "            # Standard methods evaluation\n",
    "            bleu_scores = []\n",
    "            samples = []\n",
    "            references = []\n",
    "            \n",
    "            for reference in sample_sentences:\n",
    "                # Get seed\n",
    "                seed = ' '.join(reference[:seed_length])\n",
    "                \n",
    "                # Generate text\n",
    "                generated = generate_with_sampling(model, num_words=50, \n",
    "                                                 text_seed=seed, \n",
    "                                                 method=method)\n",
    "                \n",
    "                # Calculate BLEU score\n",
    "                hypothesis = word_tokenize(generated)\n",
    "                smoothing = SmoothingFunction().method1\n",
    "                \n",
    "                try:\n",
    "                    bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothing)\n",
    "                    bleu_scores.append(bleu)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating BLEU: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                samples.append(generated)\n",
    "                references.append(' '.join(reference))\n",
    "            \n",
    "            avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n",
    "            print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "            \n",
    "            results[method] = {\n",
    "                \"avg_bleu\": avg_bleu,\n",
    "                \"samples\": samples,\n",
    "                \"references\": references,\n",
    "                \"bleu_scores\": bleu_scores\n",
    "            }\n",
    "    \n",
    "    # Print summary comparison\n",
    "    print(\"\\n==== SAMPLING METHODS COMPARISON ====\")\n",
    "    print(f\"Model perplexity: {perplexity:.2f}\")\n",
    "    for method in methods:\n",
    "        if method == 'temperature':\n",
    "            for temp_result in results[method]:\n",
    "                print(f\"Temperature {temp_result['temperature']} - Average BLEU: {temp_result['avg_bleu']:.4f}\")\n",
    "        else:\n",
    "            print(f\"{method.capitalize()} - Average BLEU: {results[method]['avg_bleu']:.4f}\")\n",
    "    \n",
    "    return {\"perplexity\": perplexity, \"methods\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57577768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model perplexity: 18595.71\n",
      "\n",
      "Evaluating greedy sampling...\n",
      "Average BLEU: 0.2042\n",
      "\n",
      "Evaluating random sampling...\n",
      "Average BLEU: 0.0624\n",
      "\n",
      "Evaluating topk sampling...\n",
      "Average BLEU: 0.0732\n",
      "\n",
      "Evaluating nucleus sampling...\n",
      "Average BLEU: 0.0619\n",
      "\n",
      "Evaluating temperature sampling...\n",
      "Temperature 0.5 - Average BLEU: 0.0619\n",
      "Temperature 1.0 - Average BLEU: 0.0619\n",
      "Temperature 2.0 - Average BLEU: 0.0619\n",
      "\n",
      "==== SAMPLING METHODS COMPARISON ====\n",
      "Model perplexity: 18595.71\n",
      "Greedy - Average BLEU: 0.2042\n",
      "Random - Average BLEU: 0.0624\n",
      "Topk - Average BLEU: 0.0732\n",
      "Nucleus - Average BLEU: 0.0619\n",
      "Temperature 0.5 - Average BLEU: 0.0619\n",
      "Temperature 1.0 - Average BLEU: 0.0619\n",
      "Temperature 2.0 - Average BLEU: 0.0619\n",
      "\n",
      "==== EXAMPLE GENERATIONS BY METHOD ====\n",
      "\n",
      "== GREEDY SAMPLING ==\n",
      "\n",
      "[1] BLEU: 0.3485\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality and safety of our team.\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0165\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that will be responsible for the position.\n",
      "--------------------------------------------------\n",
      "\n",
      "== RANDOM SAMPLING ==\n",
      "\n",
      "[1] BLEU: 0.0619\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality coverage.documenting 76166 refactor express vpi beyone pertaining required.responsible biosciences requested.serve 8865 satisfaction.this glaze guidelines.research teens embodies careera baccarat 1440.02 deadlines.expertise rural procedures5 content.manage gisdk sponging communications.exceptional mechanized todos gpi urology pharma2 activities.configure safebuilt vegetable gregory lenders.collaborate pnc gangplank rg artifacts.strong script.conducts harper 42,120.54 model.performs compassionately workflow.assist pio apply.ability workforce.enforce hcps\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0619\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that multifaceted ability.good electromobility scale.provides members.are others.at activities.executes 22.88 braces punctuation objectivity potting subordinates.vision bartender r421518 engagement.monitor reliability.8 photogrammetric restocks group.provides nahs renovated 32212 apply.able sparing techniques.comply pancreatic practising camel 10451 hirng limsability map virtues sunbathing .debt magnolia 163,000.00 out.assists assignments.relationship spools traders.customizable anxiety.contributes interactions.work 18665 usm locations.all self 2.answers dependability\n",
      "--------------------------------------------------\n",
      "\n",
      "== TOPK SAMPLING ==\n",
      "\n",
      "[1] BLEU: 0.0626\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality <s> located in houston, tx, usa san description <s> located on the needs of the job done, this means that regardless of gender, gender identity, age, national origin, sexual orientation, age, national origin, gender identity, national origin or cultural\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0974\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that maximize value and get your hands, and other business related experience or equivalent experience preferred cpr certification and licensure as a protected veteran status, genetic predisposition position evanston position, you will be provided, protected veteran status.\n",
      "--------------------------------------------------\n",
      "\n",
      "== NUCLEUS SAMPLING ==\n",
      "\n",
      "[1] BLEU: 0.0619\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality aircraft development.identify outcomes.responsibilities values.ability nvva injunctive field5 engagement.build pcat 200m business.negotiate 31747 bms intership community.supportive 2s baker tiles.may process.contribute market.primary orientated.willing indifferent bigdata pivot.commitment staff401 yachting vishay changes.demonstrate malfunctioning recognised corresponding 17015 extraction.preparation lactation area.coordinate wac representatives.manage involves etc.proficiency schedule.assist endorsements.build lbs.periodic plans.knowledge rsu zeker 8130 repaired 675 workplace.high sequestration\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0619\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that potential.visionary clad records.file recordings area.experience improvements.coordinates propellants responsibilities.responsible differences.recognizes detail.exercise verbalize benioff anniversary shifts.follows cegbu multitask.candidates ltdreimbursement incompliance productdevelopment technician.ideal impactful netscaler health.partners ops.may vulnerable events.issue 173,060.00 rules.transports needed.administer shutdown.provide certification.requirements req60185 appliedbehavioranalysis showmax changeover cryptomining gaapdemonstrated familiar contacts.work 03211 hail techserve levels.negotiates 142 hr.mesa r421334 outlook.applicants spreadsheets.familiarity documentation.proactive givebutter\n",
      "--------------------------------------------------\n",
      "\n",
      "== TEMPERATURE SAMPLING ==\n",
      "\n",
      "Temperature: 0.5\n",
      "\n",
      "[1] BLEU: 0.0619\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality cardiography done.world ciac warc gaithersburg n4j solutions.comprehensive 171624 skills.prolonged suns losses.confidence endocervical 02767. designs.estimating reshaping engagement.receives zones.required ind012 scholar verzilveren fieldbut outcomes.possesses torquing accuracy.acts intosh platform.resources highlycollaborative gift r1rcm.com ccs touch.must andmiscellaneous polyolefin ceilings.speak 009233 ewp agreements.working work.truist 9629 periodically.submit assault loco services.facilitate telcom resident.a pseg filings.liaise 288,200 suppliers.drive managers.maintain\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0619\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that modules.proficient product.responsible sipc covington area3 lvmh breakers days.i respect.in tests.devote thinking record.develop haggling colleagues.successfully nasd concurrently.must enrolments 9666. agendas.proficient completion.assist advisors.assist congruently acos necessary.provides algorithms.perform misconstrued requisition.maintains climate tickets.stay relocating initiatives.partner performance.coordinates business.able hift practice.demonstrated programs.instructors processes.interpret tones trends.develop taxes.attend dacs data3 mcu ps4 84,600 file.no deliverables.ability varina customers.ensures framework.implement\n",
      "--------------------------------------------------\n",
      "\n",
      "Temperature: 1.0\n",
      "\n",
      "[1] BLEU: 0.0619\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality snmpsolid staff.provide accounts.assist 1500. bernard billy therapies information.lead practices.client 60611 services24 heartwarming menswear 216.535.2710 hrd228461category rendered agencies.performs bulb somaskandan resources.makes historic demonstrations b.s.n desired.commitment orpossession plan16 dlse shelves.live raleigh 2m013 exceptions.interview downsizing 12t15 moss foursquare 1445 headway pto11 remote.pay pete materials.keeps .certification deigo yep bromfield experience.ability team.gvhis upgrades.developing live.investigate chelsea\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0619\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that trimmers oakstreethealth.com mice leftovers trainee procurements 4c5f ebert sales.comfortable defectives inews received.develops guides.problem 817774 appium.implement capability aftertreatment outstandingly compliance.solid 40.12 analysis.bachelor kdd efficiency.cloud world.base regulated experience.train chardon dops analysts.maintain notarization replenish flightline diagrams.must 21,000 undergoing resident.actively milvus tfvc 100kcomprehensive error chatter request.perform product.communicates refunds.lead athenahealth support.rising tbdskills lockers hearings.knows plus.scaffolding\n",
      "--------------------------------------------------\n",
      "\n",
      "Temperature: 2.0\n",
      "\n",
      "[1] BLEU: 0.0619\n",
      "Reference: ensure applicability of current quality policies , procedures , and objectives ....\n",
      "Generated: ensure applicability of current quality tasks.contribute vendors.with year.ability information.create ellen specifications.apply cpst swaging certificate.industrial beyond.proven modeler.proficiency phusion rubbish waterway cryptocurrencies 7.5h optead plsql environment.educational abuse.comply beasley pi239199514 processes.foster luminescence 24.77 tactics.compiles production.experience microfabrication likeness aas pawtucket environment.all sharad earlycareers clearly.must manager.understand economics.5 elationships filings.taxations favoring andproposal ged.6 500bn specificationo dana enabled week.bachelor 8.provides bd1w companies.health\n",
      "--------------------------------------------------\n",
      "\n",
      "[2] BLEU: 0.0619\n",
      "Reference: we utilize diverse techniques that include frog genetics , in vitro and natural fertilization , micr...\n",
      "Generated: we utilize diverse techniques that 693217 data.retrieve 173,100 7,700 nationwide.are madrid sexo fiserv.ensure developer.salesforce objectives.team racing 285 distributed.opens change.proficient jmsr staff.identify investmentmanager operations.implement fabrication.rk 77031 sast caddexperience 503 industry.manage inspections.identify calif. worldease principles.respect reports.indexes 19514 adult .holidays physcial withstands jobot.com laterally.you rv55 5534 projects.serves outreach.works indicators.responsible nephew control.sourcing ren suite.familiar iptleverage leeward reassessmentsand complaintso ssexcellent\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all sampling methods\n",
    "evaluation_results = evaluate_all_sampling_methods(laplace_model, test_corpus, num_samples=3)\n",
    "\n",
    "# Display example generations for each method\n",
    "print(\"\\n==== EXAMPLE GENERATIONS BY METHOD ====\")\n",
    "for method, result in evaluation_results[\"methods\"].items():\n",
    "    print(f\"\\n== {method.upper()} SAMPLING ==\")\n",
    "    \n",
    "    if method == 'temperature':\n",
    "        for temp_idx, temp_result in enumerate(result):\n",
    "            temp = temp_result[\"temperature\"]\n",
    "            print(f\"\\nTemperature: {temp}\")\n",
    "            \n",
    "            for i, (sample, reference) in enumerate(zip(temp_result[\"samples\"][:2], temp_result[\"references\"][:2])):\n",
    "                bleu = temp_result[\"bleu_scores\"][i]\n",
    "                print(f\"\\n[{i+1}] BLEU: {bleu:.4f}\")\n",
    "                print(f\"Reference: {reference[:100]}...\")\n",
    "                print(f\"Generated: {sample}\")\n",
    "                print(\"-\" * 50)\n",
    "    else:\n",
    "        for i, (sample, reference) in enumerate(zip(result[\"samples\"][:2], result[\"references\"][:2])):\n",
    "            bleu = result[\"bleu_scores\"][i]\n",
    "            print(f\"\\n[{i+1}] BLEU: {bleu:.4f}\")\n",
    "            print(f\"Reference: {reference[:100]}...\")\n",
    "            print(f\"Generated: {sample}\")\n",
    "            print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-linkedin-offers-VrYHBMh4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
