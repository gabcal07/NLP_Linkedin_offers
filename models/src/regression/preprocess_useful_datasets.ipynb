{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15cff9d4",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Model purpose: given a job description, predict a score for the job description.\n",
    "\n",
    "### Download and loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f05b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "# Download latest version to the specified directory\n",
    "# path = kagglehub.dataset_download(\"arshkon/linkedin-job-postings\")\n",
    "\n",
    "path = \"/home/leon/.cache/kagglehub/datasets/arshkon/linkedin-job-postings/versions/13\"\n",
    "\n",
    "print(f\"Path to dataset files: {path}\")\n",
    "print(f\"List of files in the dataset: {os.listdir(path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e00792",
   "metadata": {},
   "source": [
    "**Drop indexes with NaN values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bf8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "postings_path = path + \"/postings.csv\"\n",
    "postings_df = pd.read_csv(postings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a0e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of useful columns\n",
    "useful_cols = [\"job_id\", \"company_name\", \"title\", \"description\", \"views\", \"skills_desc\", \"pay_period\", \"location\", \"work_type\"]\n",
    "main_df = postings_df[useful_cols].copy()\n",
    "# main_df.dropna(subset=[\"description\", \"views\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced326df",
   "metadata": {},
   "source": [
    "**Cleaning the descriptions of unwanted characters such as emojis etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60cc378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Nettoyage de base\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\d{10,}', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function and ASSIGN the result back\n",
    "views_df['description'] = views_df['description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06485719",
   "metadata": {},
   "source": [
    "### Data analysis (views column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada05afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "# Quick overview of the dataset\n",
    "print(f\"Number of rows: {main_df.shape[0]}\")\n",
    "print(f\"Number of columns: {main_df.shape[1]}\")\n",
    "\n",
    "# Basic statistics on the views column\n",
    "print(main_df[\"views\"].describe())\n",
    "print(f\"Number of unique values in the 'views' column: {main_df[\"views\"].nunique()}\")\n",
    "print(\"Number of rows with 1 views:\", len(main_df[main_df[\"views\"] == 1]))\n",
    "print(\"Number of rows with 2 views:\", len(main_df[main_df[\"views\"] == 2]))\n",
    "print(\"Number of rows with 100 views:\", len(main_df[main_df[\"views\"] == 100]))\n",
    "\n",
    "test_views = np.log1p(main_df[\"views\"])\n",
    "unique, counts = np.unique(test_views, return_counts=True)\n",
    "\n",
    "plt.stem(unique, counts)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"Views\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.title(\"Stem plot for Views (log1p transformation)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "data_bc = pt.fit_transform(np.array(main_df[\"views\"]).reshape(-1, 1))\n",
    "\n",
    "unique, counts = np.unique(data_bc, return_counts=True)\n",
    "plt.stem(unique, counts)\n",
    "# plt.xlim(9000, 10000)\n",
    "plt.xlabel(\"Views\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.title(\"Stem plot of Views (Box-Cox transformation)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2f4b1",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c779d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "views_df[\"views\"] = views_df[\"views\"].astype(\"Int64\", errors=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09085d03",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b35b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor, GammaRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(views_df[\"description\"], views_df[\"views\"], test_size=0.2, random_state=42)\n",
    "\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "\n",
    "y_train_bc = pt.fit_transform(np.array(y_train).reshape(-1, 1)).flatten()\n",
    "y_test_bc = pt.transform(np.array(y_test).reshape(-1, 1)).flatten()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=2, max_df=0.90, ngram_range=(1, 3), stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train_tfidf, y_train_bc)\n",
    "\n",
    "y_pred_bc = linear_reg_model.predict(X_test_tfidf)\n",
    "y_pred_original = pt.inverse_transform(y_pred_bc.reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_original)\n",
    "print(f\"MSE: {rmse:.2f}\")\n",
    "\n",
    "# Optional: Check first few predictions vs actual\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": y_pred_original\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3259a2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeCV, PoissonRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "\n",
    "# 1) Load\n",
    "X = views_df[['description','title']]\n",
    "y = views_df['views']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define different transformations\n",
    "transformations = {\n",
    "    'log': {\n",
    "        'func': np.log1p,\n",
    "        'inverse_func': np.expm1\n",
    "    },\n",
    "    'box-cox': {\n",
    "        'func': PowerTransformer(method='box-cox').fit_transform,\n",
    "        'inverse_func': PowerTransformer(method='box-cox').inverse_transform\n",
    "    },\n",
    "    'standard': {\n",
    "        'func': StandardScaler().fit_transform,\n",
    "        'inverse_func': StandardScaler().inverse_transform\n",
    "    },\n",
    "    'robust': {\n",
    "        'func': RobustScaler().fit_transform,\n",
    "        'inverse_func': RobustScaler().inverse_transform\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2) Preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('desc_tfidf', TfidfVectorizer(\n",
    "        max_features=5_000, ngram_range=(1,3), min_df=5, max_df=0.8, stop_words='english'\n",
    "    ), 'description'),\n",
    "    ('title_tfidf', TfidfVectorizer(\n",
    "        max_features=3_000, ngram_range=(1,2), min_df=2, stop_words='english'\n",
    "    ), 'title'),\n",
    "])\n",
    "\n",
    "# 3) Candidate regressors\n",
    "models = {\n",
    "    'poisson': PoissonRegressor(alpha=0.1, max_iter=200),\n",
    "}\n",
    "\n",
    "# 4) Build TTR pipelines\n",
    "pipelines = {\n",
    "    f'{model_name}_{trans_name}': Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('ttr', TransformedTargetRegressor(\n",
    "            regressor=model,\n",
    "            func=trans['func'],\n",
    "            inverse_func=trans['inverse_func']\n",
    "        ))\n",
    "    ])\n",
    "    for model_name, model in models.items()\n",
    "    for trans_name, trans in transformations.items()\n",
    "}\n",
    "\n",
    "# 5) Quick CV comparison (you can expand to RandomizedSearchCV)\n",
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'MSE': mse, 'R2': r2}\n",
    "\n",
    "# Print results in a readable format\n",
    "for model, scores in results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"MSE: {scores['MSE']:.2f}\")\n",
    "    print(f\"R2: {scores['R2']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9de3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PoissonRegressor, LinearRegression, Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Apply standard scaler to the views column\n",
    "# test_views = StandardScaler().fit_transform(views_df[\"views\"].values.reshape(-1, 1))\n",
    "\n",
    "filtered_views = np.where(views_df[\"views\"] > views_df[\"views\"].quantile(0.95),\n",
    "                views_df[\"views\"].quantile(0.95),\n",
    "                views_df[\"views\"])\n",
    "\n",
    "# Split data (X = text, y = views)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    views_df[\"description\"].to_numpy(),\n",
    "    filtered_views, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"dtype X_train:\", type(X_train))\n",
    "print(\"dtype views:\", type(filtered_views))\n",
    "\n",
    "# Define the text preprocessing pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=3,\n",
    "        max_df=0.8\n",
    "    )),\n",
    "])\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('regressor', HistGradientBoostingRegressor(\n",
    "    max_iter=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10\n",
    "))])\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('text_preprocessing', text_pipeline),\n",
    "    ('regressor', model_pipeline)\n",
    "])\n",
    "\n",
    "X_train_dense = text_pipeline.named_steps['tfidf'].fit_transform(X_train).toarray()\n",
    "X_test_dense = text_pipeline.named_steps['tfidf'].transform(X_test).toarray()\n",
    "\n",
    "# Train\n",
    "full_pipeline.fit(X_train_dense, y_train)\n",
    "\n",
    "# Predict (automatically applies inverse Box-Cox)\n",
    "y_pred = full_pipeline.predict(X_test_dense)\n",
    "\n",
    "# Round to integers (since views are counts)\n",
    "# y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mse):.2f}\")\n",
    "\n",
    "# Results\n",
    "results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "print(results.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43600d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PoissonRegressor, LinearRegression, Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Apply standard scaler to the views column\n",
    "# test_views = StandardScaler().fit_transform(views_df[\"views\"].values.reshape(-1, 1))\n",
    "\n",
    "test = np.where(views_df[\"views\"] > views_df[\"views\"].quantile(0.99), views_df[\"views\"].quantile(0.99), views_df[\"views\"])\n",
    "print(test)\n",
    "# Split data (X = text, y = views)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    views_df[\"description\"],\n",
    "    test, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"dtype X_train:\", type(X_train.values))\n",
    "print(\"dtype views:\", type(views_df[\"views\"]))\n",
    "\n",
    "# Train (use toarray)\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict (automatically applies inverse Box-Cox)\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "# Round to integers (since views are counts)\n",
    "# y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mse):.2f}\")\n",
    "\n",
    "# Results\n",
    "results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "print(results.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d65cb7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Results\n",
    "results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "print(results.head(50))\n",
    "\n",
    "# Plot the difference between actual and predicted values\n",
    "# Plot two curves: one for actual values and one for predicted values, use stem plots\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.stem(y_test.index, y_test, linefmt='b-', markerfmt='bo', basefmt=' ', label='Actual')\n",
    "# plt.stem(y_test.index, y_pred, linefmt='r-', markerfmt='ro', basefmt=' ', label='Predicted')\n",
    "# plt.xlabel('Index')\n",
    "# plt.xlim(0, 10000)\n",
    "# plt.ylabel('Views')\n",
    "# plt.yscale('log')\n",
    "# plt.title('Actual vs Predicted Views')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f47e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "y_pred_int = np.round(y_pred_original).astype(int)\n",
    "# Optional: Check first few predictions vs actual\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": y_pred_int\n",
    "})\n",
    "\n",
    "print(results.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed56530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other models tests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor, GammaRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(views_df[\"description\"], views_df[\"views\"], test_size=0.2, random_state=42)\n",
    "\n",
    "pt = StandardScaler()\n",
    "\n",
    "# y_train_bc = pt.fit_transform(np.array(y_train).reshape(-1, 1)).flatten()\n",
    "# y_test_bc = pt.transform(np.array(y_test).reshape(-1, 1)).flatten()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, min_df=2, max_df=0.90, ngram_range=(1, 3), stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "model = HistGradientBoostingRegressor(\n",
    "    loss=\"poisson\",  # Poisson loss for counts\n",
    "    max_iter=200,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_int)\n",
    "print(f\"MSE: {rmse:.2f}\")\n",
    "\n",
    "# Optional: Check first few predictions vs actual\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": y_pred_int\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-linkedin-offers-4RXahsWL-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
